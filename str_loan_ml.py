# -*- coding: utf-8 -*-
"""Str_Loan_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17B6w5dT722y8kNyLUogtp-TMhxIes_nm

# Loan Prediction using Machine Learning

### In this project, we will predict whether a customer will get the loan from bank or not.

Following Factors are:
1. Gender
2. Education
3. Marrital status
4. Loand Amount
5. Credit History
6. Account Balance
7. Property Area
8. Credit History
9. Dependants
10. Self Employment Status

There are more factors also, let see in this notebook
"""

import pandas as pd
import numpy as np

# import os
# os.chdir('C:/Loan-Prediction-Classification')

## Pandas
## Numpy
## SKlearn
## Matplotlib

train=pd.read_csv('./Loan_Data/train.csv')
train.Loan_Status=train.Loan_Status.map({'Y':1,'N':0})

"""## Check the missing Values in data"""

train.isnull().sum()

"""## Preprocessing on the data"""

Loan_status=train.Loan_Status
train.drop('Loan_Status',axis=1,inplace=True)
test=pd.read_csv('./Loan_Data/test.csv')
Loan_ID=test.Loan_ID
data=train.append(test)
data.head()

data.shape

data.describe()

data.isnull().sum()

data.Dependents.dtypes

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline 
corrmat=data.corr()
f,ax=plt.subplots(figsize=(9,9))
sns.heatmap(corrmat,vmax=.8,square=True)

"""## Label ENcode"""

## Label encoding for gender
data.Gender=data.Gender.map({'Male':1,'Female':0})
data.Gender.value_counts()

## Let's see correlations
corrmat=data.corr()
f,ax=plt.subplots(figsize=(9,9))
sns.heatmap(corrmat,vmax=.8,square=True)

## Labelling 0 & 1 for Marrital status
data.Married=data.Married.map({'Yes':1,'No':0})

data.Married.value_counts()

## Labelling 0 & 1 for Dependents
data.Dependents=data.Dependents.map({'0':0,'1':1,'2':2,'3+':3})

data.Dependents.value_counts()

## Let's see correlations for it
corrmat=data.corr()
f,ax=plt.subplots(figsize=(9,9))
sns.heatmap(corrmat,vmax=.8,square=True)

## Labelling 0 & 1 for Education Status
data.Education=data.Education.map({'Graduate':1,'Not Graduate':0})

data.Education.value_counts()

## Labelling 0 & 1 for Employment status
data.Self_Employed=data.Self_Employed.map({'Yes':1,'No':0})

data.Self_Employed.value_counts()

data.Property_Area.value_counts()

## Labelling 0 & 1 for Property area
data.Property_Area=data.Property_Area.map({'Urban':2,'Rural':0,'Semiurban':1})

data.Property_Area.value_counts()

corrmat=data.corr()
f,ax=plt.subplots(figsize=(9,9))
sns.heatmap(corrmat,vmax=.8,square=True)

data.head()

data.Credit_History.size

"""## It's time to fill the missing values"""

data.Credit_History.fillna(np.random.randint(0,2),inplace=True)

data.isnull().sum()

data.Married.fillna(np.random.randint(0,2),inplace=True)

data.isnull().sum()

## Filling with median
data.LoanAmount.fillna(data.LoanAmount.median(),inplace=True)

## Filling with mean
data.Loan_Amount_Term.fillna(data.Loan_Amount_Term.mean(),inplace=True)

data.isnull().sum()

data.Gender.value_counts()

## Filling Gender with random number between 0-2
from random import randint 
data.Gender.fillna(np.random.randint(0,2),inplace=True)

data.Gender.value_counts()

## Filling Dependents with median
data.Dependents.fillna(data.Dependents.median(),inplace=True)

data.isnull().sum()

corrmat=data.corr()
f,ax=plt.subplots(figsize=(9,9))
sns.heatmap(corrmat,vmax=.8,square=True)

data.Self_Employed.fillna(np.random.randint(0,2),inplace=True)

data.isnull().sum()

data.head()

## Dropping Loan ID from data, it's not useful
data.drop('Loan_ID',inplace=True,axis=1)

data.isnull().sum()

data.head()

"""## Split the Data into X & Y"""

train_X=data.iloc[:614,] ## all the data in X (Train set)
train_y=Loan_status  ## Loan status will be our Y

from sklearn.model_selection import train_test_split
train_X,test_X,train_y,test_y=train_test_split(train_X,train_y,random_state=0)

#sc_f = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']
#sc_f = ['ApplicantIncome','CoapplicantIncome','LoanAmount']
train_X.head()

# train_X.head()

test_X.head()

"""## Using Different types of Machine Learning Model"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

"""## Fit the all ML Models"""

models=[]
models.append(("Logistic Regression",LogisticRegression()))
models.append(("Decision Tree",DecisionTreeClassifier()))
models.append(("Linear Discriminant Analysis",LinearDiscriminantAnalysis()))
models.append(("Random Forest",RandomForestClassifier()))
models.append(("Support Vector Classifier",SVC()))
models.append(("K- Neirest Neighbour",KNeighborsClassifier()))
models.append(("Naive Bayes",GaussianNB()))

scoring='accuracy'

from sklearn.model_selection import KFold 
from sklearn.model_selection import cross_val_score
result=[]
names=[]

for name,model in models:
    # kfold=KFold(n_splits=10,random_state=0)
    cv_result=cross_val_score(model,train_X,train_y,scoring=scoring)
    result.append(cv_result)
    names.append(name)
    print(model)
    print("%s %f" % (name,cv_result.mean()))

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

LR=LogisticRegression()
LR.fit(train_X,train_y)
pred=LR.predict(test_X)
print("Model Accuracy:- ",accuracy_score(test_y,pred))
print(confusion_matrix(test_y,pred))
print(classification_report(test_y,pred))

print(pred)

X_test=data.iloc[614:,] 
# X_test[sc_f]=SC.fit_transform(X_test[sc_f])

X_test.head()

prediction = LR.predict(X_test)

print(prediction)

## TAken data from the dataset
t = LR.predict([[0.0,	0.0,	0.0,	1,	0.0,	1811,	1666.0,	54.0,	360.0,	1.0,	2]])

print(t)

import pickle
# now you can save it to a file
file = './Model/ML_Model1.pkl'
with open(file, 'wb') as f:
    pickle.dump(file, f)

with open(file, 'rb') as f:
    k = pickle.load(f)


